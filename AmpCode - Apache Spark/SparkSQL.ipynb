{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe7bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required module\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97729f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "builder.\\\n",
    "appName(\"sparksql\").\\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce8059c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.2\n"
     ]
    }
   ],
   "source": [
    "# see the latest version\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a089b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Spark to read a CSV file named \"operations_management.csv\" and load it into a DataFrame named \"data.\" \n",
    "\n",
    "data = spark.read.format('csv').\\\n",
    "option('inferSchema','true').\\\n",
    "option('header', 'true').\\\n",
    "option('path','operations_management.csv').\\\n",
    "load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42514aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- description: string (nullable = true)\n",
      " |-- industry: string (nullable = true)\n",
      " |-- level: integer (nullable = true)\n",
      " |-- size: string (nullable = true)\n",
      " |-- line_code: string (nullable = true)\n",
      " |-- value: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check  schema for data\n",
    "\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e54acae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new DataFrame named \"data_2\" that contains only the \"industry\" and \"value\" columns \n",
    "# from the original \"data\" DataFrame, with rows filtered based on the specified conditions, \n",
    "# and sorted in descending order by the \"value\" column.\n",
    "\n",
    "data_2 = data.select(\"industry\",\"value\").\\\n",
    "filter((col(\"value\") > 200) & (col(\"industry\") != \"total\")).\\\n",
    "orderBy(desc(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab6f2331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- industry: string (nullable = true)\n",
      " |-- value: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #check schema\n",
    "\n",
    "data_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d861f8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            industry|value|\n",
      "+--------------------+-----+\n",
      "|        Construction| 6030|\n",
      "|        Construction| 5904|\n",
      "|        Construction| 5229|\n",
      "|Accommodation & f...| 5058|\n",
      "|        Construction| 4965|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show the latest top 5\n",
    "\n",
    "data_2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2240bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a temporary view in Spark SQL named \"data\" using the \"data_2\" DataFrame. \n",
    "\n",
    "data_2.createOrReplaceTempView(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22c0472a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            industry|value|\n",
      "+--------------------+-----+\n",
      "|        Construction| 6030|\n",
      "|        Construction| 5904|\n",
      "|        Construction| 5229|\n",
      "|Accommodation & f...| 5058|\n",
      "|        Construction| 4965|\n",
      "|        Construction| 4959|\n",
      "|Accommodation & f...| 4950|\n",
      "|        Construction| 4686|\n",
      "|        Construction| 4668|\n",
      "|        Construction| 4665|\n",
      "|       Manufacturing| 4662|\n",
      "|       Manufacturing| 4632|\n",
      "|        Construction| 4575|\n",
      "|        Construction| 4566|\n",
      "|Professional, sci...| 4476|\n",
      "|Professional, sci...| 4470|\n",
      "|        Retail trade| 4434|\n",
      "|        Retail trade| 4434|\n",
      "|Accommodation & f...| 4251|\n",
      "|Accommodation & f...| 4176|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run SparkSQL \n",
    "\n",
    "spark.sql(\"\"\"SELECT industry, value \n",
    "FROM data \n",
    "WHERE value > 200 \n",
    "AND industry != \"total\"\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85979ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
